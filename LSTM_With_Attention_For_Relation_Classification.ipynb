{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LSTM With Attention For Relation Classification.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "ltQAiEHgiH-d",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "https://github.com/teffland/Relation-Extraction/tree/master/SemEval2010_task8_all_data/SemEval2010_task8_training\n",
        "\n",
        "https://www.depends-on-the-definition.com/attention-lstm-relation-classification/\n",
        "\n",
        "https://github.com/tsterbak/keras_attention\n",
        "\n",
        "https://github.com/davidsbatista/Annotated-Semantic-Relationships-Datasets\n",
        "\n",
        "https://github.com/teffland/Relation-Extraction/tree/master/SemEval2010_task8_all_data/SemEval2010_task8_training"
      ]
    },
    {
      "metadata": {
        "id": "649DI-VQtZw8",
        "colab_type": "code",
        "outputId": "bbd76a68-ec42-489c-fbfd-0e3ab871fe55",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "49t7qucjqh3d",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Load Data"
      ]
    },
    {
      "metadata": {
        "id": "Ix-w9xqMV0W1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "with open('/content/drive/My Drive/Cause_Effect/TRAIN_FILE.TXT') as f:\n",
        "    train_file = f.readlines()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "QNR79g4TV-CW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def prepare_dataset(raw):\n",
        "    sentences, relations = [], []\n",
        "    to_replace = [(\"\\\"\", \"\"), (\"\\n\", \"\"), (\"<\", \" <\"), (\">\", \"> \")]\n",
        "    last_was_sentence = False\n",
        "    for line in raw:\n",
        "        sl = line.split(\"\\t\")\n",
        "        if last_was_sentence:\n",
        "            relations.append(sl[0].split(\"(\")[0].replace(\"\\n\", \"\"))\n",
        "            last_was_sentence = False\n",
        "        if sl[0].isdigit():\n",
        "            sent = sl[1]\n",
        "            for rp in to_replace:\n",
        "                sent = sent.replace(rp[0], rp[1])\n",
        "            sentences.append(sent)\n",
        "            last_was_sentence = True\n",
        "    print(\"Found {} sentences\".format(len(sentences)))\n",
        "    return sentences, relations"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "HczPuPxKV-FE",
        "colab_type": "code",
        "outputId": "a91d9c78-63c4-4d72-856b-9cab8a9f9ae1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "sentences, relations = prepare_dataset(train_file)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 8000 sentences\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "F5wJoPRFV-Hb",
        "colab_type": "code",
        "outputId": "b63c0f93-f1fc-4d13-8bb9-30285d89de1a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "cell_type": "code",
      "source": [
        "sentences[156]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'For those of you who are unsure what Afrikaans is, it is a language which originated from the Dutch which were the first settlers in South Africa and the unique  <e1> language </e1>  was evolved from other  <e2> settlers </e2>  from Malaya, Indonesia, Madagascar and West Africa.'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "metadata": {
        "id": "ZuiaPcU1V-J0",
        "colab_type": "code",
        "outputId": "4c8255a7-7762-486a-8391-5e6a6c95cd9d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "relations[156]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Entity-Origin'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "metadata": {
        "id": "fQrMwfvbV-Mj",
        "colab_type": "code",
        "outputId": "04fcf715-1ede-460e-8f40-a0c38e9ff776",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "cell_type": "code",
      "source": [
        "n_relations = len(set(relations))\n",
        "print(\"Found {} relations\\n\".format(n_relations))\n",
        "print(\"Relations:\\n{}\".format(list(set(relations))))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 10 relations\n",
            "\n",
            "Relations:\n",
            "['Entity-Destination', 'Message-Topic', 'Cause-Effect', 'Instrument-Agency', 'Other', 'Product-Producer', 'Member-Collection', 'Content-Container', 'Entity-Origin', 'Component-Whole']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "b35BONG8V-PE",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def call(self, h, mask=None):\n",
        "    h_shape = K.shape(h)\n",
        "    d_w, T = h_shape[0], h_shape[1]\n",
        "    \n",
        "    logits = K.dot(h, self.w)  # w^T h\n",
        "    logits = K.reshape(logits, (d_w, T))\n",
        "    alpha = K.exp(logits - K.max(logits, axis=-1, keepdims=True))  # exp\n",
        "    alpha = alpha / K.sum(alpha, axis=1, keepdims=True)  # softmax\n",
        "    r = K.sum(h * K.expand_dims(alpha), axis=1)  # r = h*alpha^T\n",
        "    h_star = K.tanh(r)  # h^* = tanh(r)\n",
        "    return h_star"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "gXSxErG0p0OB",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Setup A Sequence Model"
      ]
    },
    {
      "metadata": {
        "id": "Og_qpTnAuNZ3",
        "colab_type": "code",
        "outputId": "f93d8a35-1ed7-479e-a418-fd02193909d9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "from keras.models import Model, Input\n",
        "from keras.layers import Dense, LSTM, Dropout, Embedding, SpatialDropout1D, Bidirectional, concatenate, InputSpec\n",
        "from keras.layers import GlobalAveragePooling1D, GlobalMaxPooling1D\n",
        "from keras.optimizers import Adam, RMSprop\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.preprocessing import MultiLabelBinarizer, LabelEncoder\n",
        "import regex as re\n",
        "import pickle\n",
        "import numpy as np\n",
        "\n",
        "from keras.engine.topology import Layer\n",
        "from keras import initializers as initializers, regularizers, constraints\n",
        "from keras import backend as K\n",
        "\n",
        "class KerasTextClassifier(BaseEstimator, TransformerMixin):\n",
        "    '''Wrapper class for keras text classification models that takes raw text as input.'''\n",
        "    \n",
        "    def __init__(self, max_words=30000, input_length=50, emb_dim=50, n_classes=10):\n",
        "        self.max_words = max_words\n",
        "        self.input_length = input_length\n",
        "        self.emb_dim = emb_dim\n",
        "        self.n_classes = n_classes\n",
        "        self.return_attention = True\n",
        "        self.model = self._get_model()\n",
        "        self.encoder = LabelEncoder()\n",
        "        self.tokenizer = Tokenizer(num_words=self.max_words+1, filters='!\"#$%&()*+,-.:;=?@[\\\\]^_`{|}~\\t\\n', lower=True, split=' ', oov_token=\"UNK\")\n",
        "    \n",
        "    def _get_model(self):\n",
        "        d = 0.5\n",
        "        rd = 0.5\n",
        "        rnn_units = 128\n",
        "        input_text = Input((self.input_length,))\n",
        "        text_embedding = Embedding(input_dim=self.max_words + 2, output_dim=self.emb_dim,\n",
        "                                   input_length=self.input_length, mask_zero=True)(input_text)\n",
        "        text_embedding = SpatialDropout1D(0.5)(text_embedding)\n",
        "        bilstm = Bidirectional(LSTM(units=rnn_units, return_sequences=True, dropout=d,\n",
        "                                    recurrent_dropout=rd))(text_embedding)\n",
        "        x, attn = AttentionWeightedAverage(return_attention=True)(bilstm)\n",
        "        x = Dropout(0.5)(x)\n",
        "        out = Dense(units=self.n_classes, activation=\"softmax\")(x)\n",
        "        model = Model(input_text, out)\n",
        "        return model\n",
        "    \n",
        "    def _get_attention_map(self, texts):\n",
        "        att_model_output = self.model.layers[0:-2]\n",
        "        att_model = Model(att_model_output[0].input, att_model_output[-1].output)\n",
        "        att_model.compile(optimizer=RMSprop(),\n",
        "                          loss=\"sparse_categorical_crossentropy\",\n",
        "                          metrics=[\"accuracy\"])\n",
        "        return att_model.predict(self._get_sequences(texts))[1]\n",
        "    \n",
        "    def _get_sequences(self, texts):\n",
        "        seqs = self.tokenizer.texts_to_sequences(texts)\n",
        "        return pad_sequences(seqs, maxlen=self.input_length,\n",
        "                             value=0, padding='post', truncating='post')\n",
        "    \n",
        "    def _labels(self, labels):\n",
        "        return self.encoder.transform(labels)\n",
        "    \n",
        "    def fit(self, X, y, X_val=None, y_val=None, lr=0.001, resume=False,\n",
        "            epochs=10, batch_size=32):\n",
        "        '''\n",
        "        Fit the vocabulary and the model.\n",
        "        \n",
        "        :params:\n",
        "        X: list of texts\n",
        "        y: labels\n",
        "        X_val: list of texts for validation\n",
        "        y_val: labels for validation.\n",
        "        '''\n",
        "        self.model.compile(optimizer=RMSprop(clipnorm=10., lr=lr),\n",
        "                           loss=\"sparse_categorical_crossentropy\",\n",
        "                           metrics=[\"accuracy\"])\n",
        "        \n",
        "        if not resume:\n",
        "            self.tokenizer.fit_on_texts(X)\n",
        "            self.encoder.fit(y)\n",
        "            self.tokenizer.word_index = {e: i for e,i in self.tokenizer.word_index.items() if i <= self.max_words}\n",
        "            self.tokenizer.word_index[self.tokenizer.oov_token] = self.max_words + 1\n",
        "        else:\n",
        "            print(\"Resuming training...\")\n",
        "        seqs = self._get_sequences(X)\n",
        "        categorical_y = self._labels(y)\n",
        "        print(\"Fit text model with {} classes\".format(len(self.encoder.classes_)))\n",
        "        if X_val:\n",
        "            val_seqs = self._get_sequences(X_val)\n",
        "            categorical_y_val = self._labels(y_val)\n",
        "            self.model.fit(seqs, categorical_y, batch_size=batch_size,\n",
        "                           epochs=epochs, validation_data=(val_seqs, categorical_y_val))\n",
        "        else:\n",
        "            self.model.fit(seqs, categorical_y, batch_size=batch_size,\n",
        "                           epochs=epochs, validation_split=0.1)\n",
        "    \n",
        "    def predict_proba(self, X, y=None):\n",
        "        return self.model.predict(self._get_sequences(X))\n",
        "    \n",
        "    def predict(self, X, y=None):\n",
        "        return np.argmax(self.predict_proba(X), axis=1)\n",
        "    \n",
        "    def save(self, path=\"model\"):                               \n",
        "        self.model.save_weights('{}_weights.h5'.format(path))          \n",
        "        with open(\"{}_index.pkl\".format(path), \"wb\") as f:                      \n",
        "            pickle.dump([self.encoder, self.tokenizer, self.max_words,\n",
        "                         self.emb_dim, self.input_length, self.n_classes], f)         \n",
        "            \n",
        "    def load(self, path=\"model\"):                                                              \n",
        "        with open(\"{}_index.pkl\".format(path), \"rb\") as f:\n",
        "            self.encoder, self.tokenizer, self.max_words, self.emb_dim, self.input_length, self.n_classes = pickle.load(f)                                                                     \n",
        "        self.model = self._get_model()                                           \n",
        "        self.model.load_weights('{}_weights.h5'.format(path))\n",
        "        \n",
        "        \n",
        "class AttentionWeightedAverage(Layer):\n",
        "    \"\"\"\n",
        "    Computes a weighted average attention mechanism from:\n",
        "        Zhou, Peng, Wei Shi, Jun Tian, Zhenyu Qi, Bingchen Li, Hongwei Hao and Bo Xu.\n",
        "        “Attention-Based Bidirectional Long Short-Term Memory Networks for Relation Classification.”\n",
        "        ACL (2016). http://www.aclweb.org/anthology/P16-2034\n",
        "    How to use:\n",
        "    see: [BLOGPOST]\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, return_attention=False, **kwargs):\n",
        "        self.init = initializers.get('uniform')\n",
        "        self.supports_masking = True\n",
        "        self.return_attention = return_attention\n",
        "        super(AttentionWeightedAverage, self).__init__(** kwargs)\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        self.input_spec = [InputSpec(ndim=3)]\n",
        "        assert len(input_shape) == 3\n",
        "\n",
        "        self.w = self.add_weight(shape=(input_shape[2], 1),\n",
        "                                 name='{}_w'.format(self.name),\n",
        "                                 initializer=self.init)\n",
        "        self.trainable_weights = [self.w]\n",
        "        super(AttentionWeightedAverage, self).build(input_shape)\n",
        "\n",
        "    def call(self, h, mask=None):\n",
        "        h_shape = K.shape(h)\n",
        "        d_w, T = h_shape[0], h_shape[1]\n",
        "        \n",
        "        logits = K.dot(h, self.w)  # w^T h\n",
        "        logits = K.reshape(logits, (d_w, T))\n",
        "        alpha = K.exp(logits - K.max(logits, axis=-1, keepdims=True))  # exp\n",
        "        \n",
        "        # masked timesteps have zero weight\n",
        "        if mask is not None:\n",
        "            mask = K.cast(mask, K.floatx())\n",
        "            alpha = alpha * mask\n",
        "        alpha = alpha / K.sum(alpha, axis=1, keepdims=True) # softmax\n",
        "        r = K.sum(h * K.expand_dims(alpha), axis=1)  # r = h*alpha^T\n",
        "        h_star = K.tanh(r)  # h^* = tanh(r)\n",
        "        if self.return_attention:\n",
        "            return [h_star, alpha]\n",
        "        return h_star\n",
        "\n",
        "    def get_output_shape_for(self, input_shape):\n",
        "        return self.compute_output_shape(input_shape)\n",
        "\n",
        "    def compute_output_shape(self, input_shape):\n",
        "        output_len = input_shape[2]\n",
        "        if self.return_attention:\n",
        "            return [(input_shape[0], output_len), (input_shape[0], input_shape[1])]\n",
        "        return (input_shape[0], output_len)\n",
        "\n",
        "    def compute_mask(self, input, input_mask=None):\n",
        "        if isinstance(input_mask, list):\n",
        "            return [None] * len(input_mask)\n",
        "        else:\n",
        "            return None"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "dcshKHHhprhy",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "KxDcBgZGprky",
        "colab_type": "code",
        "outputId": "b447627a-86f2-414b-b487-dfbaf0b1c357",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        }
      },
      "cell_type": "code",
      "source": [
        "kclf = KerasTextClassifier(input_length=50, n_classes=n_relations, max_words=15000)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "LB2kMSFKprni",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "tr_sent, te_sent, tr_rel, te_rel = train_test_split(sentences, relations, test_size=0.1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "uZS4zth5prp9",
        "colab_type": "code",
        "outputId": "0d8210b8-1f97-46f4-b666-ddcd342a493a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 853
        }
      },
      "cell_type": "code",
      "source": [
        "kclf.fit(X=tr_sent, y=tr_rel, X_val=te_sent, y_val=te_rel,\n",
        "         batch_size=10, lr=0.001, epochs=20)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fit text model with 10 classes\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_grad.py:102: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Deprecated in favor of operator or tf.math.divide.\n",
            "Train on 7200 samples, validate on 800 samples\n",
            "Epoch 1/20\n",
            "7200/7200 [==============================] - 84s 12ms/step - loss: 2.1416 - acc: 0.2254 - val_loss: 1.8688 - val_acc: 0.3300\n",
            "Epoch 2/20\n",
            "7200/7200 [==============================] - 82s 11ms/step - loss: 1.8603 - acc: 0.3267 - val_loss: 1.6375 - val_acc: 0.4238\n",
            "Epoch 3/20\n",
            "7200/7200 [==============================] - 81s 11ms/step - loss: 1.6610 - acc: 0.4019 - val_loss: 1.5092 - val_acc: 0.4475\n",
            "Epoch 4/20\n",
            "7200/7200 [==============================] - 82s 11ms/step - loss: 1.5400 - acc: 0.4403 - val_loss: 1.4122 - val_acc: 0.4800\n",
            "Epoch 5/20\n",
            "7200/7200 [==============================] - 82s 11ms/step - loss: 1.3978 - acc: 0.4918 - val_loss: 1.3811 - val_acc: 0.5138\n",
            "Epoch 6/20\n",
            "7200/7200 [==============================] - 82s 11ms/step - loss: 1.3143 - acc: 0.5318 - val_loss: 1.3050 - val_acc: 0.5438\n",
            "Epoch 7/20\n",
            "7200/7200 [==============================] - 82s 11ms/step - loss: 1.2241 - acc: 0.5682 - val_loss: 1.2563 - val_acc: 0.5688\n",
            "Epoch 8/20\n",
            "7200/7200 [==============================] - 81s 11ms/step - loss: 1.1266 - acc: 0.5990 - val_loss: 1.2077 - val_acc: 0.6088\n",
            "Epoch 9/20\n",
            "7200/7200 [==============================] - 81s 11ms/step - loss: 1.0627 - acc: 0.6328 - val_loss: 1.1729 - val_acc: 0.6013\n",
            "Epoch 10/20\n",
            "7200/7200 [==============================] - 82s 11ms/step - loss: 0.9841 - acc: 0.6610 - val_loss: 1.1213 - val_acc: 0.6375\n",
            "Epoch 11/20\n",
            "7200/7200 [==============================] - 81s 11ms/step - loss: 0.9117 - acc: 0.6821 - val_loss: 1.1429 - val_acc: 0.6288\n",
            "Epoch 12/20\n",
            "7200/7200 [==============================] - 81s 11ms/step - loss: 0.8521 - acc: 0.7094 - val_loss: 1.1472 - val_acc: 0.6313\n",
            "Epoch 13/20\n",
            "7200/7200 [==============================] - 82s 11ms/step - loss: 0.7937 - acc: 0.7329 - val_loss: 1.1182 - val_acc: 0.6413\n",
            "Epoch 14/20\n",
            "7200/7200 [==============================] - 81s 11ms/step - loss: 0.7497 - acc: 0.7396 - val_loss: 1.1342 - val_acc: 0.6425\n",
            "Epoch 15/20\n",
            "7200/7200 [==============================] - 80s 11ms/step - loss: 0.6967 - acc: 0.7626 - val_loss: 1.1655 - val_acc: 0.6275\n",
            "Epoch 16/20\n",
            "7200/7200 [==============================] - 80s 11ms/step - loss: 0.6653 - acc: 0.7756 - val_loss: 1.1224 - val_acc: 0.6300\n",
            "Epoch 17/20\n",
            "7200/7200 [==============================] - 80s 11ms/step - loss: 0.6254 - acc: 0.7900 - val_loss: 1.1658 - val_acc: 0.6625\n",
            "Epoch 18/20\n",
            "7200/7200 [==============================] - 81s 11ms/step - loss: 0.5860 - acc: 0.8019 - val_loss: 1.1922 - val_acc: 0.6600\n",
            "Epoch 19/20\n",
            "7200/7200 [==============================] - 81s 11ms/step - loss: 0.5636 - acc: 0.8140 - val_loss: 1.1573 - val_acc: 0.6613\n",
            "Epoch 20/20\n",
            "7200/7200 [==============================] - 80s 11ms/step - loss: 0.5332 - acc: 0.8244 - val_loss: 1.1879 - val_acc: 0.6538\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "nLqIBtR3p7zQ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Investigate Attention"
      ]
    },
    {
      "metadata": {
        "id": "ND4zPKtnprsq",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.style.use(\"ggplot\")\n",
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1Fao4AX9prvO",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "y_pred = kclf.predict(te_sent)\n",
        "y_attn = kclf._get_attention_map(te_sent)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jcqeh0bUprxq",
        "colab_type": "code",
        "outputId": "3e3892e2-d5e1-48d5-8be7-9092d05cda79",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 619
        }
      },
      "cell_type": "code",
      "source": [
        "i = 354\n",
        "activation_map = np.expand_dims(y_attn[i][:len(te_sent[i].split())], axis=1)\n",
        "\n",
        "f = plt.figure(figsize=(8, 8))\n",
        "ax = f.add_subplot(1, 1, 1)\n",
        "\n",
        "img = ax.imshow(activation_map, interpolation='none', cmap='gray')\n",
        "\n",
        "plt.xlim([0,0.5])\n",
        "ax.set_aspect(0.1)\n",
        "ax.set_yticks(range(len(te_sent[i].split())))\n",
        "ax.set_yticklabels(te_sent[i].split());\n",
        "ax.grid()\n",
        "plt.title(\"Attention map of sample {}\\nTrue relation: {}\\nPredicted relation: {}\"\n",
        "          .format(i, te_rel[i], kclf.encoder.classes_[y_pred[i]]));\n",
        "\n",
        "# add colorbar\n",
        "cbaxes = f.add_axes([0.2, 0, 0.6, 0.03]);\n",
        "cbar = f.colorbar(img, cax=cbaxes, orientation='horizontal');\n",
        "cbar.ax.set_xlabel('Probability', labelpad=2);"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAW4AAAJaCAYAAAAPoa2pAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nJpOBO6WUmsy/IGZANqq8SdkAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 576x576 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "fhcb7olwqK0N",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Evaluate The Model"
      ]
    },
    {
      "metadata": {
        "id": "_CGid0LiqJ0D",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import f1_score, classification_report, accuracy_score"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "F3Hax-uiqJ43",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "y_test_pred = kclf.predict(te_sent)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "j0hLVDwzqJ7f",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "label_idx_to_use = [i for i, c in enumerate(list(kclf.encoder.classes_)) if  c !=\"Other\"]\n",
        "label_to_use = list(kclf.encoder.classes_)\n",
        "label_to_use.remove(\"Other\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "i8dSwvcUqJ-E",
        "colab_type": "code",
        "outputId": "8f8ecfd3-ba9e-4872-a4d1-613efc665366",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "print(\"F1-Score: {:.1%}\".format(f1_score(kclf.encoder.transform(te_rel), y_test_pred, average=\"macro\", labels=label_idx_to_use)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "F1-Score: 69.9%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "4K5WwxBbqKAt",
        "colab_type": "code",
        "outputId": "300ac512-9e35-443c-aa77-a4aeba436263",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        }
      },
      "cell_type": "code",
      "source": [
        "print(classification_report(kclf.encoder.transform(te_rel), y_test_pred, target_names=label_to_use, labels=label_idx_to_use))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                    precision    recall  f1-score   support\n",
            "\n",
            "      Cause-Effect       0.84      0.77      0.80       101\n",
            "   Component-Whole       0.59      0.62      0.60        97\n",
            " Content-Container       0.81      0.67      0.73        51\n",
            "Entity-Destination       0.80      0.90      0.85        94\n",
            "     Entity-Origin       0.70      0.76      0.73        68\n",
            " Instrument-Agency       0.57      0.68      0.62        47\n",
            " Member-Collection       0.89      0.72      0.80        69\n",
            "     Message-Topic       0.54      0.56      0.55        52\n",
            "  Product-Producer       0.53      0.71      0.60        68\n",
            "\n",
            "         micro avg       0.69      0.72      0.71       647\n",
            "         macro avg       0.70      0.71      0.70       647\n",
            "      weighted avg       0.71      0.72      0.71       647\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}